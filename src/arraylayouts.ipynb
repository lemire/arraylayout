{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Project Summary\n",
      "\n",
      "This project is about memory layouts for binary search. Using the work of Brodal, Fagerberg, and Jakob (SODA 2002) as a starting point, I wanted to know what is the fastest array layout for binary search. To be specific, I'm only interested in structures where the $n$ data items live in a single array of length $n$.  I'm interested in in-memory performance, which usually boils down to efficient cache use.\n",
      "\n",
      "The candidate layouts I considered were:\n",
      "\n",
      "- **sorted:** the usual sorted array with binary search applied to it;\n",
      "- **eytzinger:** a complete binary search tree layed out in an array using Eytzinger's method;\n",
      "- **btree:** a $B$-tree with B chosen so that B-1 keys fit into a cache line and layed out in an array using a $B$-ary generalization of Eytzinger's method;\n",
      "- **veb:** Prokop's van Emde Boas layout that is so popular from the cache-oblivous literature.\n",
      "\n",
      "I came up with this shortlist based on what I know and the preliminary results from Brodal, Fagerberg, and Jakob. Although I had some preconceptions, I have no stake in this game. None of these are my creation.\n",
      "\n",
      "The sources for this project are available at [github](https://github.com/patmorin/arraylayouts).\n",
      "\n",
      "## Preliminary Implementation\n",
      "\n",
      "I chose C++ as the implementation language: It's close to the the hardware, and C++ templates are a clean way to get generality without sacrificing performance.  The main effects I expected to study here were caching in the L1, L2, L3, and RAM memory hierarchy.  For this, we really needed a language that packs data directly into arrays.\n",
      "\n",
      "I wrote C++ implementations of all four methods described above.  Each method is implemented as a class that can be created from a sorted array.  Each class stores its data in its own array and has a `search(x)` method that returns the index (in its own array) of the smallest value greater than or equal to `x`, or returns `n` if `a` contains no value greater than or equal to `x`.  A common base class also provides a `get_data(i)` method that returns the data at index `i`.\n",
      "\n",
      "The implementations use three way (less than, greater than, and equal to) branching and use early termination in the case of equality.  No fancy optimizations were made.\n",
      "\n",
      "Most of the implementations were straightforward, with not a lot of design decisions to make. The exception was the veb implementation.  With this implementation I explored the design space a fair bit and eventually settled on an implementation that uses an array of size $h$, where $h=\\min\\{h:2^{h+1}-1 \\ge n\\}$ is the height of the veb tree.  This extra array stores the special values needed to to walk from level $i$ to level $i+1$ in the veb tree.\n",
      "\n",
      "### What I Expected\n",
      "\n",
      "After a surprising false start that has to do with the fact that [binary search is awful when $n$ is close to a power of two](http://www.pvk.ca/Blog/2012/07/30/binary-search-is-a-pathological-case-for-caches/), I formulated some hypotheses about the running-times of these different layouts.\n",
      "\n",
      "My first test machine was lauteschwein, an [Intel 4790K](http://www.cpu-world.com/CPUs/Core_i7/Intel-Core%20i7-4790K.html) with an 8MB L3 cache and 32GB of RAM.  I was mainly interested in large values of $n$, which is then really focused on the interaction between L3 cache and RAM.  I expected the following results. For simplicity, I'll assume 4-byte data and 64-byte cache lines, so we can fit 125K cache lines containing 2M data values into the cache.\n",
      "\n",
      "1. **sorted:** After enough large $n$, the top levels of the search tree can live in the cache, but these all live in different cache lines, so we can get the top $\\log(125K) = 17$ levels to live the cache, so these won't incur any cache misses.  At the end of the search, we finish by searching in a subarray whose length is smaller than 16, so the last four or five steps of the search only incur a single cache miss.  The remaining steps each cost a cache miss. In total, this is about $\\log(n)-\\log 125K-\\log 16=\\log n-21$ cache misses. Call this guess $\\log n-C_1$.  I expected this to be the slowest.\n",
      "\n",
      "2. **eytzinger:** Here, the picture is the same, but the top levels of the tree are consecutive in memory, so the top $\\log(2M)=21$ levels get to live in the cache.  Therefore, we should incur about $\\log(n)-\\log(2M)-\\log(16)=\\log n-25$ cache misses.  I expected this to be just a bit faster than sorted, $\\log n - C_2$.\n",
      "\n",
      "3. **btree:** In this implementation, we took $B=17$ so that the $B-1$ data items for a node fit into a single cache line.  As with eytzinger, we also save on the top $\\log(2M)$ levels of the tree.  In total, we expect about $\\log_{16} n-\\log_{16}(2M)=\\frac{1}{4}\\log n-17$ cache misses.  I expected this to be the fastest, at $\\frac{1}{4}\\log n- C_3$.\n",
      "\n",
      "4. **veb:** For very large $n$, I expected this to be the second fastest, for all the same reasons as the btree, except that the constant $1/4$ is wrong because veb subtrees are not aligned with cache line boundaries (they have size $2^h-1$) and they're not always close to the right size. For example, a subtree of size 31 gets split into a top tree of size 7 and bottom subtrees of size 7, missing the magical 16 by a wide margin. \n",
      "\n",
      "### What Actually Happened\n",
      "\n",
      "The [graphs of results](http://cglab.ca/~morin/misc/arraylayout/lauteschwein/run_data/) surprised me.\n",
      "\n",
      "1. **sorted:** was indeed the slowest.\n",
      "\n",
      "2. **eytzinger:** was tied with btree for first place. This was a big surprise.\n",
      "\n",
      "3. **btree:** was (tied for) the fastest. It also had the noticeably different constant of growth in front of the $\\log n$, as expected.\n",
      "\n",
      "4. **veb:** this was the second fastest for large $n$, but had a lot of overhead for small $n$.  I\n",
      "\n",
      "I was so surprised, that I tried the [same test on a few different machines](http://cglab.ca/~morin/misc/arraylayout/) and even enlisted the help of [reddit r/compsci](http://www.reddit.com/r/compsci/comments/35ad8d/alternatives_to_sorted_arrays_for_binary_searching/). The results were mostly the same, except for a few odd cases. Notably, with the old Atom 330 I used as a home theatre PC. On that machine, [the graphs](http://cglab.ca/~morin/misc/arraylayout/scray/run_data/) were pretty much as expected.\n",
      "\n",
      "It was at this point that [Paul Khuong](http://www.pvk.ca/) contacted to ask how I made my graphs. I had read a few of Paul's blog articles while preparing my code and experiments, so I used the opportunity to engage him in discussion.  \n",
      "\n",
      "Since then, Paul has done a lot of careful benchmarking on a machine he has handy and [rewrote many of the search routines](https://github.com/patmorin/arraylayout/tree/pvk) to make them faster for small values of $n$ and switched out the PRNG for a faster one.  Most the optimizations in Paul's code boil down removing branches and replacing them with conditional move instructions.  Of course, he doesn't do this in assembly, but writing C++ code like this:\n",
      "```c++\n",
      "    a = (x < a[m]) ? a : a+m\n",
      "```\n",
      "translates into a conditional move instruction in which `a+m` is moved into (the register containing) `a` if `x < a[m]`.\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Why is Eytzinger So Fast?\n",
      "\n",
      "The conclusion we initially reached is that the Eytzinger layout is so fast because of prefetching. Remember that, after accessing `a[i]` we always access `a[2*i+1]` or `a[2*i+2]`. Our guess was that the prefetcher was learning the resulting approximate geometric progression and prefetching the right memory locations for us.  It turns out, though, that prefetchers are probably not that smart. [Most can only detect constant stride access patterns](http://www.futurechips.org/chip-design-for-all/prefetching.html). \n",
      "\n",
      "Another argument against this theory is that Paul's microoptimized version of the Eytzinger code, which replaces branching with conditional move instructions was much slower than my code for large values of $n$, even though it is much faster for small values of $n$ and a disassembly clearly showed that it is simpler code.  This is weird because the memory access pattern is identical for both, and the prefetcher (presumably) only looks at the access pattern and not at which instructions were used to perform the accesses.\n",
      "\n",
      "After doing some instruction-level profiling, I found that Paul's code was stalling when accessing a memory location pointed to be a register. The contents of this register depended on a previously executed `cmov` instruction, which hadn't completed yet. The processor didn't know what to do, so it did nothing but wait for the register contents to be ready.\n",
      "\n",
      "On the other the processor speculatively loads one of the two branches in my code. Half the time it loads the right branch, which is good, and half the time it loads the wrong branch, which means it later has to flush the instruction pipeline. However, in either case it loads a sequence of instruction that access `a[2*i+1]` or `a[2*i+2]`. Just the loading an partial execution of those instructions is enough to trigger the memory subsystem to load the appropriate cache line, so it gets there sooner.  In fact, this process cascades several levels deep so that, while we're still waiting on the result of the comparison `x < a[i]`, the memory subsystem is already fetching `a[16*i+r]` for some `r` in `15,....,30`.  What's neat is that 15/16 times, this value is in the same cache line that our search will eventually need.\n",
      "\n",
      "This doesn't happen on the Atom 330, because it [doesn't do speculative execution](http://en.wikipedia.org/wiki/Intel_Atom_%28CPU%29). To test this hypothesis, I added a single prefect instruction <code>__builtin_prefetch(16*i+23, 0, 0)</code> at the top of the search loop, and indeed, this [improved the performance](http://cglab.ca/~morin/misc/arraylayout/prefetch-test/xxx/run_data/index.html) on the Atom 330.\n",
      "\n",
      "### Analysis of Eytzinger\n",
      "\n",
      "The 16 great-great granchildren of index $i$ in an Eytzinger layout are located at positions $16i+15,\\ldots,16i+30$.  If we assume that a begins on the left boundary of a cache line, then $16i+23$ is on the element at index $23 \\bmod 16 = 7$ in a cache line.  This means that if the search proceeds to any of the fifteen great-great grandchildren of $i$ in $16i+16,\\ldots,16i+30$, then that child will be in the same cache line as $16i+23$, which is what we prefetched.\n",
      "\n",
      "In an Eytzinger array, levels 0, 1, 2, and 3 are contained in the first cache line. For levels 4 and beyond, the above analysis shows that we will have prefetched the appropriate cache line 15/16 of the time and we have done so before accessing node $i$, so the prefetcher has had four rounds of search to load the appropriate cache line.\n",
      "\n",
      "Paul has pointed out that if store our Eytzinger layout with the root in `a[1]`, then all 16 great great grandchildren of a node will be stored in a single cache line.  I've tested this, and it does make the code a bit faster on some architectures.\n",
      "\n",
      "\n",
      "### Comparison with B-trees\n",
      "\n",
      "The B-tree implementation only loads a new cache line after each four rounds of binary search, but it doesn't know in advance which cache line it will need until these four iterations are done so, after four rounds of binary search, it stalls waiting on a cache line.\n",
      "\n",
      "The Eytzinger implementation loads a cache line during every round of binary search, but it can wait four rounds for this cache line to load. Thus, if memory bandwidth is unlimited, then B-trees and Eytzinger layouts shoud perform identically, and they do on many architectures.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Todo List\n",
      "\n",
      "- Hack the g++ assembly output to determine if explicit prefetches really help, or if their presence just turns off conditional moves\n",
      "\n",
      "- The performance of Eytzinger suggests that, in most cases, we have enough memory bandwidth to load a cache line at each step of the binary search. Can we add `__builtin_prefetch`es into our (branchless) btree code to increase the chances that we have already started loading the cache line we need by the time we finish with the btree node.\n",
      "\n",
      "- Can we separate the performance of btrees and eytzinger arrays by having multiple threads searching the same array. At some point, memory bandwidth should get in the way with eytzinger, but later with btrees.\n",
      "\n",
      "- ~~~Try to understand why Paul's code is so much faster for small values of $n$, but significantly slower for large $n$.~~~\n",
      "\n",
      "- Import the pieces of Paul's code that are clear wins. His hard-coded btree inner search seems like one of these.\n",
      "\n",
      "- ~~See what kind of gains we get by aligning Eytzinger~~ I tried this, and it seems not much is gained by forcing the Eytzinger alignment. There is also a good reason to avoid it.  The path to an element of rank $x2^i$ can not have more than a handful of its entries stored in a partially associative cache. This means that we create a situation where locality in the searches can be bad.\n",
      "\n",
      "- ~~Try prefetching two or even four children of a b-tree node and see if that helps.~~  There doesn't seem to be any gains to get from partially prefetching the leaves of a 16-tree.  However, it seems that a 4-tree in which we prefetch the sixteen children is a bit faster than a 16-tree with no prefetching (about 3-5%).  Unfortunately, this doesn't seem like a scalable strategy. What are we going to do with 64-bit data?\n",
      "\n",
      "- ~~~Try a version of btrees in which each node is layed out in BFS order. [Cache lines are not loaded atomically](http://en.wikipedia.org/wiki/CAS_latency), they arrive in left to right order.~~~\n",
      "\n",
      "- Design in-place algorithms for making btree and Eytzinger layouts."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Some Lower Bounds\n",
      "\n",
      "To get an idea how good our implementations are, we can compare them with some lower-bounds:\n",
      "\n",
      "1. The `fake` data structure gives a lower bound.\n",
      "2. Running the Branch-free sorted code on an array of size $100$ can be used as a lower-bound for sizes $100^2$, $100^3$, and so on.  For $100^c$, we use the lower-bound $f+ (t_{100}-f)*c$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Branch-Free Eytzinger With and Without Prefetching\n",
      "\n",
      "In the section titled Watch the Compiler (below) I discovered that using `__builtin_prefetch()` actually turned the branch-free code into branchy code, so to compare the two, I compiled the branch-free code to assembly and put the prefetching in myself.\n",
      "\n",
      "\n",
      "```console\n",
      "> g++ -std=c++11 -O4 -S -c main.cpp -o main.S\n",
      "> vi main.S\n",
      "> g++ -std=c++11 main.S -o main-x\n",
      "```\n",
      "\n",
      "And here's my modified version of the assembly code:\n",
      "\n",
      "```nasm\n",
      "\t.cfi_startproc\n",
      "\tmovq\t8(%rdi), %r9   # r9 = n (rdi = this)\n",
      "\ttestq\t%r9, %r9\n",
      "\tje\t.L131\n",
      "\tmovq\t(%rdi), %r10   # r10 = a\n",
      "\tmovq\t%r9, %rax\n",
      "\txorl\t%edx, %edx\n",
      "\t.p2align 4,,10\n",
      "\t.p2align 3\n",
      ".L130:\n",
      "\n",
      "    # I added the following three lines\n",
      "\tmovq\t%rdx, %rdi           # copy (i=rdx) into rdi\n",
      "\tsalq\t$6, %rdi             # multiply rdi by 64 (16*4bytes)\n",
      "\tprefetcht0\t92(%r10,%rdi)    # prefetch a[16*i + 23]\n",
      "\n",
      "\tmovl\t(%r10,%rdx,4), %ecx # load r10 + 4*rdx into ecx [r10 = a, rdx = i]. \n",
      "\tleaq\t(%rdx,%rdx), %rdi   # rdi = 2*i\n",
      "\tleaq\t1(%rdi), %r8        # r8 = 2*i + 1 (r8 = left)\n",
      "\taddq\t$2, %rdi            # rdi = 2*i + 2 (rdi = right)\n",
      "\tcmpl\t%esi, %ecx   # (esi = x) <= (ecx = current)\n",
      "\tcmovae\t%rdx, %rax   # j = i if x <= current\n",
      "\tmovq\t%rdi, %rdx   # rdx = 2*i + 2\n",
      "\tcmovae\t%r8, %rdx    # rdx = 2*i + 1 if x <= current\n",
      "\tcmpq\t%rdx, %r9    # compare i (rdx) and n (r9)\n",
      "\tja\t.L130\n",
      "\trep ret\n",
      ".L131:\n",
      "\txorl\t%eax, %eax\n",
      "\tret\n",
      "\t.cfi_endproc\n",
      "```\n",
      "\n",
      "Here's the results of testing with $n=10^8$ (in main-x, eytzinger_bf_a is the branch-free code with a prefetch instruction inserted manually):\n",
      "```console\n",
      "> ./main uint32 uint64 100000000 10000000\n",
      "eytzinger_bf_a uint32 uint64 100000000 10000000 0.421793 8.48813 2236029708\n",
      "eytzinger_bfp_a uint32 uint64 100000000 10000000 0.421724 3.82636 2236029708\n",
      ">\n",
      "> ./main-x uint32 uint64 100000000 10000000\n",
      "eytzinger_bf_a uint32 uint64 100000000 10000000 0.420959 3.02491 2236029708\n",
      "eytzinger_bfp_a uint32 uint64 100000000 10000000 0.420948 3.83859 2236029708\n",
      "```\n",
      "That's right; it's the record-holder at 3.02 seconds, more than twice as fast as the branch-free code without prefetching and even a lot faster than the branchy code with prefetching (3.84 seconds).\n",
      "\n",
      "And then testing with $n=1000$:\n",
      "\n",
      "```console\n",
      "> ./main uint32 uint64 100 10000000\n",
      "eytzinger_bf_a uint32 uint64 100 10000000 8.577e-06 0.743595 980000890\n",
      "eytzinger_bfp_a uint32 uint64 100 10000000 2.835e-06 1.00858 980000890\n",
      ">\n",
      "> ./main-x uint32 uint64 100 10000000\n",
      "eytzinger_bf_a uint32 uint64 100 10000000 1.3711e-05 0.766881 980000890\n",
      "eytzinger_bfp_a uint32 uint64 100 10000000 2.617e-06 1.01557 980000890\n",
      "```\n",
      "So we pay very little for the extra prefetch when n is small: .76 seconds with prefetching versus .74 without.\n",
      "\n",
      "Now I just need to figure out how to make gcc do the right thing when I use `__builtin_prefetch`. I asked [this Stack Overflow question]() but didn't get a satisfactory answer.  clang++\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Watch the Compiler\n",
      "\n",
      "The presence of `__builtin_prefetch()` instructions seems to have a profound effect on the compiler's use of conditional moves. For instance, the following two pieces of asm come from compiling the same templated function, with the template parameter `prefetch` set to `false` and `true`, respectively.  The only effect this parameter has is captured by this line of code:\n",
      "\n",
      "```c++\n",
      "\t\tif (prefetch) __builtin_prefetch(a+(multiplier*i + offset));\n",
      "```\n",
      "(`mutliplier` and `offset` are static const values.) This makes it impossible for us to determine the benefit of explicit prefetching.\n",
      "\n",
      "\n",
      "With `prefetch=false`:\n",
      "```nasm\n",
      "        .type   _ZNK3fbs15eytzinger_arrayIjmLb1EE18_branchfree_searchILb0EEEmj, @function\n",
      "_ZNK3fbs15eytzinger_arrayIjmLb1EE18_branchfree_searchILb0EEEmj:\n",
      ".LFB4646:\n",
      "        .cfi_startproc\n",
      "        movq    8(%rdi), %r9\n",
      "        testq   %r9, %r9\n",
      "        je      .L131\n",
      "        movq    (%rdi), %r10\n",
      "        movq    %r9, %rax\n",
      "        xorl    %edx, %edx\n",
      "        .p2align 4,,10\n",
      "        .p2align 3\n",
      ".L130:\n",
      "        movl    (%r10,%rdx,4), %ecx\n",
      "        leaq    (%rdx,%rdx), %rdi\n",
      "        leaq    1(%rdi), %r8\n",
      "        addq    $2, %rdi\n",
      "        cmpl    %esi, %ecx\n",
      "        cmovae  %rdx, %rax\n",
      "        movq    %rdi, %rdx\n",
      "        cmovae  %r8, %rdx\n",
      "        cmpq    %rdx, %r9\n",
      "        ja      .L130\n",
      "        rep ret\n",
      ".L131:\n",
      "        xorl    %eax, %eax\n",
      "        ret\n",
      "        .cfi_endproc\n",
      "```\n",
      "\n",
      "With `prefetch=true`:\n",
      "```nasm\n",
      "        .type   _ZNK3fbs15eytzinger_arrayIjmLb1EE18_branchfree_searchILb1EEEmj, @function\n",
      "_ZNK3fbs15eytzinger_arrayIjmLb1EE18_branchfree_searchILb1EEEmj:\n",
      ".LFB4647:\n",
      "        .cfi_startproc\n",
      "        movq    8(%rdi), %r8\n",
      "        testq   %r8, %r8\n",
      "        je      .L153\n",
      "        movq    (%rdi), %rcx\n",
      "        movq    %r8, %rax\n",
      "        xorl    %edx, %edx\n",
      "        jmp     .L151\n",
      "        .p2align 4,,10\n",
      "        .p2align 3\n",
      ".L156:\n",
      "        leaq    2(%rdx,%rdx), %rdx  # right branch i=2i+2\n",
      "        cmpq    %rdx, %r8\n",
      "        jbe     .L155\n",
      ".L151:\n",
      "        movq    %rdx, %rdi\n",
      "        salq    $6, %rdi\n",
      "        cmpl    %esi, (%rcx,%rdx,4)\n",
      "        prefetcht0      92(%rcx,%rdi)\n",
      "        jb      .L156\n",
      "        movq    %rdx, %rax          # left branch, j = i\n",
      "        leaq    1(%rdx,%rdx), %rdx  # i = 2i+1\n",
      "        cmpq    %rdx, %r8\n",
      "        ja      .L151\n",
      ".L155:\n",
      "        rep ret\n",
      ".L153:\n",
      "        xorl    %eax, %eax\n",
      "        ret\n",
      "        .cfi_endproc\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# In-Place Creation Algorithms\n",
      "\n",
      "It seems like it's easy to make a linear-time algorithm for creating an eytzinger array when $n=2^k-1$ for some integer $k$. Notice that, in this case, the leaves of the Eytzinger array, which appear appear at array locations $\\lfloor n/2\\rfloor,\\ldots,n-1$, contain the elements of ranks $0, 2, 4,\\ldots, n-1$.  So what we need to do is _unshuffle_ the array so that we get the odd numbers, occuring in sorted order, followed by the even numbers, also in sorted order.  Once we've done this, we can recurse on the first half of the array.\n",
      "\n",
      "The problem we then have is that of undoing a shuffle.  Now, doing a shuffle is [fairly easy](http://arxiv.org/abs/0805.1598), and so I guess undoing it can be done using the same algorithm.  The algorithm is a cycle-following algorithm that uses a number-theory trick to generate one element on each cycle.  Since the cycles of the inverse permutation are simply the cycles of the permutation written backwards. In particular, using the same trick we can get one element from each cycle.\n",
      "\n",
      "**Question:** What can we do when $n$ is not of the form $2^k-1$?  I this case, it gets a bit messier."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# BTree with Internal Eytzinger Layout\n",
      "\n",
      "I implemented a prototype version of the btree layout where each node is internally layed out using the Eytzinger layout.  The idea behind this is that cache lines don't load atomically, but they first load the requested memory location and then load in [left to right order](http://en.wikipedia.org/wiki/CAS_latency). Since the Eytzinger layout accesses elements in left-to-right order, I thought this might mean the search could start sooner (and hence finish sooner).\n",
      "\n",
      "The theory is nice, but it didn't pan out. The extra complexity introduced into the code seems to outweigh any benefits on modern systems.  For example, see the btree_eytzinger row in the following output:\n",
      "\n",
      "```console\n",
      "morin@lauteschwein:$ ./main uint32 uint64 100000000 20000000\n",
      "fake uint32 uint64 100000000 20000000 7.7e-08 0.0417136 2780007348\n",
      "binary uint32 uint64 100000000 20000000 0.0582541 5.60994 2780007348\n",
      "veb uint32 uint64 100000000 20000000 0.524027 4.80362 2780007348\n",
      "eytzinger uint32 uint64 100000000 20000000 0.17471 3.98417 2780007348\n",
      "eytzingerpf uint32 uint64 100000000 20000000 0.175178 3.67022 2780007348\n",
      "eytzingerpfa uint32 uint64 100000000 20000000 0.176539 3.52718 2780007348\n",
      "btree32 uint32 uint64 100000000 20000000 0.248411 4.17895 2780007348\n",
      "btree16 uint32 uint64 100000000 20000000 0.32446 4.06207 2780007348\n",
      "btree4 uint32 uint64 100000000 20000000 0.243947 4.07808 2780007348\n",
      "btree_eytzinger uint32 uint64 100000000 20000000 0.425079 4.49868 2780007348\n",
      "btreepf uint32 uint64 100000000 20000000 0.661869 3.90945 2780007348\n",
      "```\n",
      "\n",
      "I did find one exception though:  My good old Atom 330 has old fashioned SDRAM where the time until the first word becomes available is 20ns and the 8th word is 90ns.  \n",
      "\n",
      "```console\n",
      "morin@scray:~/veblayout/src$ ./main uint32 uint32 100000000 2000000\n",
      "fake uint32 uint32 100000000 2000000 2.08e-06 0.218741 3489896884\n",
      "binary uint32 uint32 100000000 2000000 0.820745 5.55008 3489896884\n",
      "veb uint32 uint32 100000000 2000000 6.16815 2.57685 3489896884\n",
      "eytzinger uint32 uint32 100000000 2000000 1.81121 5.33 3489896884\n",
      "eytzingerpf uint32 uint32 100000000 2000000 1.80252 3.55426 3489896884\n",
      "eytzingerpfa uint32 uint32 100000000 2000000 1.79738 3.3142 3489896884\n",
      "btree32 uint32 uint32 100000000 2000000 2.49543 2.46242 3489896884\n",
      "btree16 uint32 uint32 100000000 2000000 2.11352 2.34243 3489896884\n",
      "btree4 uint32 uint32 100000000 2000000 1.96299 2.69802 3489896884\n",
      "btree_eytzinger uint32 uint32 100000000 2000000 3.38417 2.25342 3489896884\n",
      "btreepf uint32 uint32 100000000 2000000 4.21723 3.02949 3489896884\n",
      "bfbtree uint32 uint32 100000000 2000000 2.11319 2.05737 3489896884\n",
      "```\n",
      "\n",
      "The only think faster was the bfbtree: A btree variant where the decision-tree is hard-coded."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Solving the mystery\n",
      "\n",
      "I wanted to understand why Paul's code is so much faster for small arrays but so much slower for big arrays.  Actually, there's no mystery as to the former, but the latter didn't make sense to me.\n",
      "\n",
      "## My Code\n",
      "Here's my original C++ code for <code>sorted_array::search(x)</code>:\n",
      "```c++\n",
      "template<typename T, typename I>\n",
      "I sorted_array<T,I>::search(const T &x) {\n",
      "\tI lo = 0;\n",
      "\tI hi = n;\n",
      "\twhile (lo < hi) {\n",
      "\t\tI m = (lo + hi) / 2;\n",
      "\t\tif (x < a[m]) {\n",
      "\t\t\thi = m;\n",
      "\t\t} else if (x > a[m]) {\n",
      "\t\t\tlo = m+1;\n",
      "\t\t} else {\n",
      "\t\t\treturn m;\n",
      "\t\t}\n",
      "\t}\n",
      "\treturn hi;\n",
      "}\n",
      "```\n",
      "\n",
      "Here's the `opannotate` disassembly when called $10^8$ times on an array of length 100 (on soprano).\n",
      "```console\n",
      "$ operf ./main uint32 uint64 100 100000000\n",
      "operf: Profiler started\n",
      "binary uint32 uint64 100 100000000 9.225e-06 2.9963 1260639663\n",
      "\n",
      "Profiling done.\n",
      "$ opannotate -D smart --assembly -t 50% main\n",
      "```\n",
      "\n",
      "```nasm\n",
      ";; rdi is 'this' pointer (which is also 'a')\n",
      ";; rsi is reference to x\n",
      "0000000000401f00 <_ZN3fbs12sorted_arrayIjmE6searchERKj.isra.14>: /* fbs::sorted_array<unsigned int, unsigned long>::search(unsigned int const&) [clone .isra.14] total:  93519 84.8591 */\n",
      "   961  0.8720 :  401f00:       mov    0x8(%rdi),%rax                                      ; rax=this->n (hi)\n",
      "    31  0.0281 :  401f04:       xor    %ecx,%ecx                                           ; rcx=0 (lo)\n",
      "     9  0.0082 :  401f06:       mov    (%rdi),%r8                                          ; r8 = this->a\n",
      "     8  0.0073 :  401f09:       cmp    %rcx,%rax                                           ; compare lo and hi                                           \n",
      "               :  401f0c:       jbe    401f42 <_ZN3fbs12sorted_arrayIjmE6searchERKj.isra.14+0x42> ; abort if lo >= hi\n",
      "  1003  0.9101 :  401f0e:       xchg   %ax,%ax                                             ; huh?\n",
      "  1502  1.3629 :  401f10:       lea    (%rcx,%rax,1),%rdx                                  ; rdx = lo + hi\n",
      "  1068  0.9691 :  401f14:       shr    %rdx                                                ; rdx = (lo + hi)/2 (m)\n",
      "   953  0.8648 :  401f17:       mov    (%r8,%rdx,4),%edi                                   ; edi = a[m]\n",
      "  9176  8.3263 :  401f1b:       cmp    %edi,%esi                                           ; compare x and a[m]\n",
      "               :  401f1d:       jae    401f35 <_ZN3fbs12sorted_arrayIjmE6searchERKj.isra.14+0x35> ; do the right thing\n",
      " 17019 15.4430 :  401f1f:       cmp    %rdx,%rcx                                           ; check lo and hi again\n",
      "  9164  8.3154 :  401f22:       mov    %rdx,%rax                                           ; rax=m\n",
      "    27  0.0245 :  401f25:       jae    401f48 <_ZN3fbs12sorted_arrayIjmE6searchERKj.isra.14+0x48> ; terminate if lo >= hi\n",
      "  2652  2.4064 :  401f27:       add    %rcx,%rdx                                           ; another round of data comparison\n",
      "  1541  1.3983 :  401f2a:       shr    %rdx                                                ; ...\n",
      "  1325  1.2023 :  401f2d:       mov    (%r8,%rdx,4),%edi                                   ; edi = a[m]\n",
      "  7504  6.8091 :  401f31:       cmp    %esi,%edi                                           ; comparison\n",
      "               :  401f33:       ja     401f1f <_ZN3fbs12sorted_arrayIjmE6searchERKj.isra.14+0x1f> ; do the right thing\n",
      " 18101 16.4248 :  401f35:       cmp    %edi,%esi                                           ; equality check\n",
      "     2  0.0018 :  401f37:       jbe    401f50 <_ZN3fbs12sorted_arrayIjmE6searchERKj.isra.14+0x50> \n",
      " 10913  9.9025 :  401f39:       lea    0x1(%rdx),%rcx                                      ; go back to top of\n",
      "  1033  0.9373 :  401f3d:       cmp    %rcx,%rax                                           ; loop if lo < hi\n",
      "  2877  2.6106 :  401f40:       ja     401f10 <_ZN3fbs12sorted_arrayIjmE6searchERKj.isra.14+0x10>\n",
      "   465  0.4219 :  401f42:       repz retq \n",
      "               :  401f44:       nopl   0x0(%rax)\n",
      "   534  0.4846 :  401f48:       repz retq \n",
      "               :  401f4a:       nopw   0x0(%rax,%rax,1)\n",
      "  5253  4.7666 :  401f50:       mov    %rdx,%rax\n",
      "   398  0.3611 :  401f53:       retq   \n",
      "               :  401f54:       data32 data32 nopw %cs:0x0(%rax,%rax,1)\n",
      "\n",
      "```\n",
      "This took a while to decipher, but there's nothing too surprising here. It's a fairly smooth distribution of costs, with the big ones being the data comparisons, accounting for about $33/84\\approx39\\%$ of the time spent in this function. With only 100 elements, everything is in the cache.\n",
      "\n",
      "\n",
      "We get a different picture when we increase the array size to $10^8$:\n",
      "```console\n",
      "$ operf ./main uint32 uint64 100000000 100000000\n",
      "operf: Profiler started\n",
      "binary uint32 uint64 100000000 100000000 0.0714125 35.2213 3483627750\n",
      "\n",
      "Profiling done.\n",
      "```\n",
      "\n",
      "```nasm\n",
      "0000000000401f00 <_ZN3fbs12sorted_arrayIjmE6searchERKj.isra.14>: /* fbs::sorted_array<unsigned int, unsigned long>::search(unsigned int const&) [clone .isra.14] total: 1272466 97.9699 */\n",
      "   921  0.0709 :  401f00:       mov    0x8(%rdi),%rax\n",
      "    40  0.0031 :  401f04:       xor    %ecx,%ecx\n",
      "    71  0.0055 :  401f06:       mov    (%rdi),%r8\n",
      "    16  0.0012 :  401f09:       cmp    %rcx,%rax\n",
      "               :  401f0c:       jbe    401f42 <_ZN3fbs12sorted_arrayIjmE6searchERKj.isra.14+0x42>\n",
      "   923  0.0711 :  401f0e:       xchg   %ax,%ax\n",
      "  6098  0.4695 :  401f10:       lea    (%rcx,%rax,1),%rdx\n",
      "  6266  0.4824 :  401f14:       shr    %rdx\n",
      "  3720  0.2864 :  401f17:       mov    (%r8,%rdx,4),%edi\n",
      "512240 39.4385 :  401f1b:       cmp    %edi,%esi                          ; stalled waiting on previous mov\n",
      "     1 7.7e-05 :  401f1d:       jae    401f35 <_ZN3fbs12sorted_arrayIjmE6searchERKj.isra.14+0x35>\n",
      " 57558  4.4315 :  401f1f:       cmp    %rdx,%rcx\n",
      " 31595  2.4326 :  401f22:       mov    %rdx,%rax\n",
      "   422  0.0325 :  401f25:       jae    401f48 <_ZN3fbs12sorted_arrayIjmE6searchERKj.isra.14+0x48>\n",
      " 10264  0.7902 :  401f27:       add    %rcx,%rdx\n",
      "  6766  0.5209 :  401f2a:       shr    %rdx\n",
      "  6025  0.4639 :  401f2d:       mov    (%r8,%rdx,4),%edi\n",
      "513073 39.5026 :  401f31:       cmp    %esi,%edi                          ; stalled waiting on previous mov\n",
      "     2 1.5e-04 :  401f33:       ja     401f1f <_ZN3fbs12sorted_arrayIjmE6searchERKj.isra.14+0x1f>\n",
      " 59406  4.5738 :  401f35:       cmp    %edi,%esi\n",
      "    23  0.0018 :  401f37:       jbe    401f50 <_ZN3fbs12sorted_arrayIjmE6searchERKj.isra.14+0x50>\n",
      " 36739  2.8286 :  401f39:       lea    0x1(%rdx),%rcx\n",
      "   393  0.0303 :  401f3d:       cmp    %rcx,%rax\n",
      " 10464  0.8056 :  401f40:       ja     401f10 <_ZN3fbs12sorted_arrayIjmE6searchERKj.isra.14+0x10>\n",
      "  2277  0.1753 :  401f42:       repz retq \n",
      "               :  401f44:       nopl   0x0(%rax)\n",
      "  1301  0.1002 :  401f48:       repz retq \n",
      "               :  401f4a:       nopw   0x0(%rax,%rax,1)\n",
      "  5416  0.4170 :  401f50:       mov    %rdx,%rax\n",
      "   446  0.0343 :  401f53:       retq   \n",
      "               :  401f54:       data32 data32 nopw %cs:0x0(%rax,%rax,1)\n",
      "```\n",
      "\n",
      "Here we spend about $79/97\\approx 81\\%$ of our time on data comparisons, which are stalled because we're waiting for the data to come in from RAM.  This is about 27 seconds of wall-clock time.\n",
      "\n",
      "## Paul's Code\n",
      "\n",
      "Paul's code tries to avoid branching:\n",
      "\n",
      "```c++\n",
      "template<typename T, typename I>\n",
      "I sorted_array<T,I,early_termination>::search(const T x) {\n",
      "        const T *base = a;\n",
      "        I n = this->n;\n",
      "\n",
      "        while (n > 1) {\n",
      "                I half = n / 2;\n",
      "                const T *ptr = &base[half];\n",
      "                const T current = *ptr;\n",
      "                base = (current < x) ? ptr : base;\n",
      "                n -= half;\n",
      "        }\n",
      "        return (*base < x) + base - a;\n",
      "}\n",
      "```\n",
      "\n",
      "And, looking at the generated assembly, it does well. The choice operator is implemented by a conditional mov and it runs more than twice as fast as my code on array of length 100.\n",
      "\n",
      "```console\n",
      "$ operf uint32 uint64 100 100000000\n",
      "$ opannotate -D smart --assembly -t 50% main\n",
      "operf: Profiler started\n",
      "binary uint32 uint64 100 100000000 2.7343e-05 1.13493 1260639663\n",
      "\n",
      "Profiling done.\n",
      "```\n",
      "\n",
      "```nasm\n",
      "0000000000404e40 <_ZN3fbs12sorted_arrayIjmLb0EE6searchEj>: /* fbs::sorted_array<unsigned int, unsigned long, false>::search(unsigned int) total:  30776 74.2539 */\n",
      "  1024  2.4706 :  404e40:       mov    0x8(%rdi),%rdx                 ; rdx = n\n",
      "    12  0.0290 :  404e44:       mov    (%rdi),%r8                     ; r8 = a = base\n",
      "               :  404e47:       cmp    $0x1,%rdx                      ; is n > 1?\n",
      "               :  404e4b:       mov    %r8,%rax                       ; rax = base\n",
      "   997  2.4055 :  404e4e:       jbe    404e69 <_ZN3fbs12sorted_arrayIjmLb0EE6searchEj+0x29> ; quit if n <= 1\n",
      "    16  0.0386 :  404e50:       mov    %rdx,%rcx                      ; rcx = n\n",
      "               :  404e53:       shr    %rcx                           ; rcx = n/2 = half\n",
      "   110  0.2654 :  404e56:       lea    (%rax,%rcx,4),%rdi             ; rdi = base + half = ptr\n",
      "  6912 16.6767 :  404e5a:       cmp    %esi,(%rdi)                    ; compare x and *ptr\n",
      "  2259  5.4503 :  404e5c:       cmovb  %rdi,%rax                      ; base rax = ptr (if *ptr < x)\n",
      "  2074  5.0040 :  404e60:       sub    %rcx,%rdx                      ; rdx = n - half\n",
      "  6147 14.8310 :  404e63:       cmp    $0x1,%rdx                      ; compare n and 1\n",
      "               :  404e67:       ja     404e50 <_ZN3fbs12sorted_arrayIjmLb0EE6searchEj+0x10> ; continue if n > 1\n",
      "               :  404e69:       cmp    %esi,(%rax)                    ; ... finish preparing the return value\n",
      "  5953 14.3629 :  404e6b:       sbb    %rdx,%rdx                      ; ...\n",
      "  1029  2.4827 :  404e6e:       and    $0x4,%edx\n",
      "   999  2.4103 :  404e71:       add    %rdx,%rax\n",
      "  1127  2.7191 :  404e74:       sub    %r8,%rax\n",
      "  1051  2.5358 :  404e77:       sar    $0x2,%rax\n",
      "  1066  2.5720 :  404e7b:       retq   \n",
      "               :  404e7c:       nopl   0x0(%rax)\n",
      "```\n",
      "Slick, and no obviously avoidable hot-spots.  Data comparisons occur at `404e5a` and `404e69/404e6b` and account for about $30/74\\approx 40\\%$ of the time spent in this function.\n",
      "\n",
      "And now on the big data:\n",
      "\n",
      "```console\n",
      "$ operf ./main uint32 uint64 100000000 100000000\n",
      "operf: Profiler started\n",
      "binary uint32 uint64 100000000 100000000 0.0692431 53.1402 3483627750\n",
      "\n",
      "Profiling done.\n",
      "```\n",
      "\n",
      "```nasm\n",
      "0000000000404e40 <_ZN3fbs12sorted_arrayIjmLb0EE6searchEj>: /* fbs::sorted_array<unsigned int, unsigned long, false>::search(unsigned int) total: 1947724 99.2345 */\n",
      "  1034  0.0527 :  404e40:       mov    0x8(%rdi),%rdx\n",
      "    19 9.7e-04 :  404e44:       mov    (%rdi),%r8\n",
      "               :  404e47:       cmp    $0x1,%rdx\n",
      "               :  404e4b:       mov    %r8,%rax\n",
      "  1002  0.0511 :  404e4e:       jbe    404e69 <_ZN3fbs12sorted_arrayIjmLb0EE6searchEj+0x29>\n",
      "     6 3.1e-04 :  404e50:       mov    %rdx,%rcx\n",
      "               :  404e53:       shr    %rcx\n",
      " 14212  0.7241 :  404e56:       lea    (%rax,%rcx,4),%rdi\n",
      " 13076  0.6662 :  404e5a:       cmp    %esi,(%rdi)\n",
      "1864357 94.987 :  404e5c:      cmovb  %rdi,%rax                          ; holy crap! 94% of the time we're stuck here\n",
      " 30734  1.5659 :  404e60:       sub    %rcx,%rdx\n",
      " 12157  0.6194 :  404e63:       cmp    $0x1,%rdx\n",
      "               :  404e67:       ja     404e50 <_ZN3fbs12sorted_arrayIjmLb0EE6searchEj+0x10>\n",
      "               :  404e69:       cmp    %esi,(%rax)\n",
      "  6104  0.3110 :  404e6b:       sbb    %rdx,%rdx\n",
      "   956  0.0487 :  404e6e:       and    $0x4,%edx\n",
      "  1054  0.0537 :  404e71:       add    %rdx,%rax\n",
      "  1022  0.0521 :  404e74:       sub    %r8,%rax\n",
      "  1023  0.0521 :  404e77:       sar    $0x2,%rax\n",
      "   968  0.0493 :  404e7b:       retq   \n",
      "               :  404e7c:       nopl   0x0(%rax)\n",
      "```\n",
      "\n",
      "Holy crap: 53 seconds (compared to 35) and 95% is the time is spent on data comparisons.  Data comparisons account for about 50 seconds of wall-clock time.  I don't believe this is caused by my code doing fewer comparisons, but let's enable early termination in Paul's code, just to be sure:\n",
      "\n",
      "```console\n",
      "$ operf ./main uint32 uint64 100000000 100000000\n",
      "operf: Profiler started\n",
      "binary uint32 uint64 100000000 100000000 0.0711805 61.4036 3483627750\n",
      "\n",
      "Profiling done.\n",
      "```\n",
      "\n",
      "Nope, it's even slower.  Let's look at the profile:\n",
      "\n",
      "```nasm\n",
      "0000000000404f80 <_ZN3fbs12sorted_arrayIjmLb1EE6searchEj>: /* fbs::sorted_array<unsigned int, unsigned long, true>::search(unsigned int) total: 2235046 99.2059 */\n",
      "  1035  0.0459 :  404f80:       mov    0x8(%rdi),%rdx\n",
      "    23  0.0010 :  404f84:       mov    (%rdi),%r9\n",
      "     2 8.9e-05 :  404f87:       cmp    $0x1,%rdx\n",
      "               :  404f8b:       jbe    404fdd <_ZN3fbs12sorted_arrayIjmLb1EE6searchEj+0x5d>\n",
      "               :  404f8d:       mov    %rdx,%rdi\n",
      "   985  0.0437 :  404f90:       mov    %r9,%rcx\n",
      "     2 8.9e-05 :  404f93:       shr    %rdi\n",
      "     1 4.4e-05 :  404f96:       lea    (%r9,%rdi,4),%rax\n",
      "     1 4.4e-05 :  404f9a:       mov    (%rax),%r8d\n",
      "  1145  0.0508 :  404f9d:       cmp    %esi,%r8d\n",
      "               :  404fa0:       jne    404fba <_ZN3fbs12sorted_arrayIjmLb1EE6searchEj+0x3a>\n",
      "               :  404fa2:       jmp    404fd5 <_ZN3fbs12sorted_arrayIjmLb1EE6searchEj+0x55>\n",
      "               :  404fa4:       nopl   0x0(%rax)\n",
      "   898  0.0399 :  404fa8:       mov    %rdx,%rdi\n",
      "  1286  0.0571 :  404fab:       shr    %rdi\n",
      " 22656  1.0056 :  404fae:       lea    (%rcx,%rdi,4),%rax\n",
      "  1041  0.0462 :  404fb2:       mov    (%rax),%r8d\n",
      "2096287 93.0469 :  404fb5:      cmp    %esi,%r8d\n",
      "     3 1.3e-04 :  404fb8:       je     404fd5 <_ZN3fbs12sorted_arrayIjmLb1EE6searchEj+0x55>\n",
      " 23563  1.0459 :  404fba:       cmp    %r8d,%esi\n",
      "  1350  0.0599 :  404fbd:       cmova  %rax,%rcx\n",
      " 69232  3.0730 :  404fc1:       sub    %rdi,%rdx\n",
      "  1012  0.0449 :  404fc4:       cmp    $0x1,%rdx\n",
      "               :  404fc8:       ja     404fa8 <_ZN3fbs12sorted_arrayIjmLb1EE6searchEj+0x28>\n",
      "               :  404fca:       cmp    %esi,(%rcx)\n",
      "  3107  0.1379 :  404fcc:       sbb    %rax,%rax\n",
      "   489  0.0217 :  404fcf:       and    $0x4,%eax\n",
      "   526  0.0233 :  404fd2:       add    %rcx,%rax\n",
      "  5438  0.2414 :  404fd5:       sub    %r9,%rax\n",
      "  3504  0.1555 :  404fd8:       sar    $0x2,%rax\n",
      "  1460  0.0648 :  404fdc:       retq   \n",
      "               :  404fdd:       mov    %r9,%rcx\n",
      "               :  404fe0:       jmp    404fca <_ZN3fbs12sorted_arrayIjmLb1EE6searchEj+0x4a>\n",
      "               :  404fe2:       nopw   %cs:0x0(%rax,%rax,1)\n",
      "               :  404fec:       nopl   0x0(%rax)\n",
      "\n",
      "```\n",
      "\n",
      "Still a huge expensive data comparison (the equality test) stuck waiting on the data `mov`.\n",
      "\n",
      "~~~Conclusion: The hardware prefetcher is ill-equipped to deal with branch-free code.  We saw this with the Eytzinger layout (which is easy to fix using `__builtin_prefetch`) and it seems to happen here as well.  Unfortunately, it's not so easy to fix.~~~\n",
      "\n",
      "!!Conclusion\n",
      "\n",
      "What seems to be happening is that my branchy code speculatively executes one of the two branches `x < a[m]` or `x > a[m]` and half the time guesses right.  When this happens, the instructions that update `hi` or `lo` and `m=(lo+hi)/2` as well as the next access to `a[m]` enter the instruction pipeline.  In particular, early on in the pipeline, the instruction to load `a[m]` puts the memory subsystem to work fetching `a[m]`.\n",
      "\n",
      "On the other hand, Paul's branch free code keeps shoving instructions into the pipleline until the next access to memory. [pointed to by `rsi` in the first snippet and `rax` in the second snippet.] At this point, it's being asked to access the memory pointed to by a register whose contents depend on the conditional move.  It doesn't know what to do, so it does nothing but wait for the conditional move to complete.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}